{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": false,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "01-cleaning_and_nlp.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loi_f63soYVr",
        "colab_type": "text"
      },
      "source": [
        "# Coding Exercise, CSML1010 Nov 24 2019\n",
        "## Pete Gray\n",
        "\n",
        "---------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkOQ3k22pXdA",
        "colab_type": "text"
      },
      "source": [
        "## **Part 1:** Using code from https://medium.com/@datanizing/modern-text-mining-with-python-part-1-of-5-introduction-cleaning-and-linguistics-647f9ec85b6a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "eaT2h6O1nSBm",
        "colab_type": "text"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Read-data-from-tsv-source\" data-toc-modified-id=\"Read-data-from-tsv-source-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Read data from tsv source</a></span></li><li><span><a href=\"#Connect-to-database\" data-toc-modified-id=\"Connect-to-database-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Connect to database</a></span></li><li><span><a href=\"#Save-subreddit-category-info\" data-toc-modified-id=\"Save-subreddit-category-info-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Save subreddit category info</a></span></li><li><span><a href=\"#Cleaning-function\" data-toc-modified-id=\"Cleaning-function-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Cleaning function</a></span></li><li><span><a href=\"#Create-new-column-in-dataframe\" data-toc-modified-id=\"Create-new-column-in-dataframe-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create new column in dataframe</a></span></li><li><span><a href=\"#Load-spaCy\" data-toc-modified-id=\"Load-spaCy-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Load spaCy</a></span></li><li><span><a href=\"#Iterate-over-all-rows-and-perform-NLP\" data-toc-modified-id=\"Iterate-over-all-rows-and-perform-NLP-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Iterate over all rows and perform NLP</a></span></li><li><span><a href=\"#Check-results\" data-toc-modified-id=\"Check-results-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Check results</a></span></li><li><span><a href=\"#Save-to-database\" data-toc-modified-id=\"Save-to-database-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Save to database</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4NUyQZQnSBp",
        "colab_type": "text"
      },
      "source": [
        "# Preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i72mPmFnSBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjQmJLg6nSBw",
        "colab_type": "text"
      },
      "source": [
        "## Read data from tsv source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-11T18:25:50.316246Z",
          "start_time": "2018-12-11T18:25:37.226960Z"
        },
        "scrolled": true,
        "id": "4TSsbsKqnSBy",
        "colab_type": "code",
        "outputId": "afb2d7ae-ca4b-4409-ae19-38fbcae8dbfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "df = pd.read_csv(\"rspct.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-65a6ef190c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rspct.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 59144"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM12Q5qNnSB2",
        "colab_type": "text"
      },
      "source": [
        "Check if data is correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALDoZOPAnSB4",
        "colab_type": "code",
        "outputId": "f847e904-175a-4771-8d10-2ed6227db3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>selftext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6d8knd</td>\n",
              "      <td>talesfromtechsupport</td>\n",
              "      <td>Remember your command line switches...</td>\n",
              "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58mbft</td>\n",
              "      <td>teenmom</td>\n",
              "      <td>So what was Matt \"addicted\" to?</td>\n",
              "      <td>Did he ever say what his addiction was or is h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8f73s7</td>\n",
              "      <td>Harley</td>\n",
              "      <td>No Club Colors</td>\n",
              "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6ti6re</td>\n",
              "      <td>ringdoorbell</td>\n",
              "      <td>Not door bell, but floodlight mount height.</td>\n",
              "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>77sxto</td>\n",
              "      <td>intel</td>\n",
              "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
              "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407526</th>\n",
              "      <td>4n9i9m</td>\n",
              "      <td>BeardedDragons</td>\n",
              "      <td>Thinking about building my own habitat</td>\n",
              "      <td>I'm thinking 4 feet long 2 feet wide an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407527</th>\n",
              "      <td>6b09ve</td>\n",
              "      <td>SkincareAddiction</td>\n",
              "      <td>[routine help] chemical exfoliants?</td>\n",
              "      <td>My skin: dry near bottom of cheeks. Very oily ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407528</th>\n",
              "      <td>5wz0js</td>\n",
              "      <td>SampleSize</td>\n",
              "      <td>[REPOST] [ACADEMIC] Consumer Insight into Red ...</td>\n",
              "      <td>Evening all,&lt;lb&gt;Would seriously appreciate it ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407529</th>\n",
              "      <td>6i2a7a</td>\n",
              "      <td>thesopranos</td>\n",
              "      <td>Changes with each rewatch</td>\n",
              "      <td>Most of users posting in this subreddit have s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407530</th>\n",
              "      <td>569ncx</td>\n",
              "      <td>ableton</td>\n",
              "      <td>How to stop samples from fading, and keep thei...</td>\n",
              "      <td>Rather new still, but when I place samples int...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>407531 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...                                           selftext\n",
              "0       6d8knd  ...  Hi there,  <lb>The usual. Long time lerker, fi...\n",
              "1       58mbft  ...  Did he ever say what his addiction was or is h...\n",
              "2       8f73s7  ...  Funny story. I went to college in Las Vegas. T...\n",
              "3       6ti6re  ...  I know this is a sub for the 'Ring Doorbell' b...\n",
              "4       77sxto  ...  Prime95 (regardless of version) and OCCT both,...\n",
              "...        ...  ...                                                ...\n",
              "407526  4n9i9m  ...         I'm thinking 4 feet long 2 feet wide an...\n",
              "407527  6b09ve  ...  My skin: dry near bottom of cheeks. Very oily ...\n",
              "407528  5wz0js  ...  Evening all,<lb>Would seriously appreciate it ...\n",
              "407529  6i2a7a  ...  Most of users posting in this subreddit have s...\n",
              "407530  569ncx  ...  Rather new still, but when I place samples int...\n",
              "\n",
              "[407531 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig6ds2OinSB8",
        "colab_type": "text"
      },
      "source": [
        "## Connect to database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seHULqzsnSB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sqlite3\n",
        "con = sqlite3.connect('selfposts.db')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxsdwx6AnSCC",
        "colab_type": "text"
      },
      "source": [
        "## Save subreddit category info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nROV-K1qnSCE",
        "colab_type": "code",
        "outputId": "984ad98d-935f-4f3d-ccff-70d46767d26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "pd.read_csv(\"subreddit_info.csv\").to_sql(\"categories\", con)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a7293beb7b29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subreddit_info.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"categories\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2710\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2712\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2713\u001b[0m         )\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1747\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m         )\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fail\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 644\u001b[0;31m                     \u001b[0;34m\"Table '{name}' already exists.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m                 )\n\u001b[1;32m    646\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Table 'categories' already exists."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7udZhKkJnSCI",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APqmmwo8nSCJ",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctg2OlsXnSCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def clean(s):\n",
        "    s = s.replace(r'<lb>', \"\\n\")\n",
        "    s = s.replace(r'<tab>', \"\\i\")\n",
        "    s = re.sub(r'<br */*>', \"\\n\", s)\n",
        "    s = s.replace(\"&lt;\", \"<\").replace(\"&gt;\", \">\").replace(\"&amp;\", \"&\")\n",
        "    s = s.replace(\"&amp;\", \"&\")\n",
        "    # markdown urls\n",
        "    s = re.sub(r'\\(https*://[^\\)]*\\)', \"\", s)\n",
        "    # normal urls\n",
        "    s = re.sub(r'https*://[^\\s]*', \"\", s)\n",
        "    s = re.sub(r'_+', ' ', s)\n",
        "    s = re.sub(r'\"+', '\"', s)\n",
        "    return str(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmUAz8ConSCP",
        "colab_type": "text"
      },
      "source": [
        "## Create new column in dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0M6eW8LnSCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"selftext_clean\"] = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIWWygCBnSCU",
        "colab_type": "text"
      },
      "source": [
        "# Iterate and clean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "177mRPBcnSCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, row in df.iterrows():\n",
        "    df.at[i, \"selftext_clean\"] = clean(row.selftext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ecr4awlnSCU",
        "colab_type": "text"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukxXWf7onSCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L75iqChDnSCe",
        "colab_type": "text"
      },
      "source": [
        "# NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynhqSwDunSCe",
        "colab_type": "text"
      },
      "source": [
        "## Load spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMNfxFA1nSCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1l-paPPnSCe",
        "colab_type": "text"
      },
      "source": [
        "## Iterate over all rows and perform NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IGiQ5hfnSCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, row in df.iterrows():\n",
        "    if i % 1000 == 0:\n",
        "        print(i)\n",
        "    if(row[\"selftext_clean\"] and len(str(row[\"selftext_clean\"])) < 1000000):\n",
        "        doc = nlp(str(row[\"selftext_clean\"]))\n",
        "        adjectives = []\n",
        "        nouns = []\n",
        "        verbs = []\n",
        "        lemmas = []\n",
        "\n",
        "        for token in doc:\n",
        "            lemmas.append(token.lemma_)\n",
        "            if token.pos_ == \"ADJ\":\n",
        "                adjectives.append(token.lemma_)\n",
        "            if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n",
        "                nouns.append(token.lemma_)\n",
        "            if token.pos_ == \"VERB\":\n",
        "                verbs.append(token.lemma_)\n",
        "                \n",
        "        df.at[i, \"selftext_lemma\"] = \" \".join(lemmas)                \n",
        "        df.at[i, \"selftext_nouns\"] = \" \".join(nouns)\n",
        "        df.at[i, \"selftext_adjectives\"] = \" \".join(adjectives)\n",
        "        df.at[i, \"selftext_verbs\"] = \" \".join(verbs)\n",
        "        df.at[i, \"selftext_nav\"] = \" \".join(nouns+adjectives+verbs)\n",
        "        df.at[i, \"no_tokens\"] = len(lemmas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQdL3PkynSCo",
        "colab_type": "text"
      },
      "source": [
        "## Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9_JnCudnSCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa6qxMhqnSCo",
        "colab_type": "text"
      },
      "source": [
        "## Save to database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFdiqd0WnSCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_sql('posts_nlp', con)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQnOuIYSqNR0",
        "colab_type": "text"
      },
      "source": [
        "## End of Part 1\n",
        "\n",
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWaPk57LqDRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tImPFlPIqG5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}