{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "loi_f63soYVr"
   },
   "source": [
    "# CSML1010 Project Working Copy\n",
    "# Sentiment Analysis with the Sentiment140 dataset\n",
    "## Pete Gray\n",
    "\n",
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4NUyQZQnSBp"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8i72mPmFnSBq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, linewidth=80)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import model_evaluation_utils as meu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdxmVNijmdOs"
   },
   "source": [
    "# Adjust pandas display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTTBG34mmWF0"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 30\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.precision = 2\n",
    "pd.options.display.max_colwidth = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB0TDJgcm8bj"
   },
   "source": [
    "# Import matplotlib and seaborn and adjust defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFdcwFgZm6Zl"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjQmJLg6nSBw"
   },
   "source": [
    "## Read data from local filesystem and csv source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:25:50.316246Z",
     "start_time": "2018-12-11T18:25:37.226960Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4TSsbsKqnSBy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MM12Q5qNnSB2"
   },
   "source": [
    "Check data with quick visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "ALDoZOPAnSB4",
    "outputId": "2b0b817e-5dce-40ac-df23-e2be2169a50d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599994</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best feeling ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599995</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interviews!  â« http://blip.fm/~8bmta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599996</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me for details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599997</td>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599998</td>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
       "0        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "...     ..         ...                           ...       ...   \n",
       "1599994  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599995  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "         _TheSpecialOne_  \\\n",
       "0        scotthamilton     \n",
       "1        mattycus          \n",
       "2        ElleCTF           \n",
       "3        Karoli            \n",
       "4        joy_wolf          \n",
       "...           ...          \n",
       "1599994  AmandaMarie1028   \n",
       "1599995  TheWDBoards       \n",
       "1599996  bpbabe            \n",
       "1599997  tinydiamondz      \n",
       "1599998  RyanTrevMorris    \n",
       "\n",
       "        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0        is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!     \n",
       "1        @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                           \n",
       "2        my whole body feels itchy and like its on fire                                                                      \n",
       "3        @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.      \n",
       "4        @Kwesidei not the whole crew                                                                                        \n",
       "...                                ...                                                                                       \n",
       "1599994  Just woke up. Having no school is the best feeling ever                                                             \n",
       "1599995  TheWDB.com - Very cool to hear old Walt interviews!  â« http://blip.fm/~8bmta                                      \n",
       "1599996  Are you ready for your MoJo Makeover? Ask me for details                                                            \n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur                                                    \n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H                                                       \n",
       "\n",
       "[1599999 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJhQcLA0u6CJ"
   },
   "source": [
    "## Give dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kS9biLKkt49y"
   },
   "outputs": [],
   "source": [
    "df.columns = ['sentiment', 'ID', 'Time', 'none', 'username', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "2CVq6zMunwkN",
    "outputId": "9902caab-b5aa-429b-b572-b6e898af9ce1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    1599999\n",
       "ID           1599999\n",
       "Time         1599999\n",
       "none         1599999\n",
       "username     1599999\n",
       "Text         1599999\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VSn5zWau-3L"
   },
   "source": [
    "## Now it has columns, this seems better.\n",
    "#\n",
    "## We have to cut this down to size, for iterative development.\n",
    "##\n",
    "## Don't forget to get rid of this!!! When crunching whole huge dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set temporary dataset size, for quicker processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_size = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    4000\n",
       "ID           4000\n",
       "Time         4000\n",
       "none         4000\n",
       "username     4000\n",
       "Text         4000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_row = int(800000-(dev_data_size/2))-1\n",
    "finish_row = int(800000+(dev_data_size/2))-1\n",
    "df_sm = df[start_row:finish_row]\n",
    "df_sm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5gpJp0ULn_mZ",
    "outputId": "10669616-4836-443d-f214-a8e30b637e92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment', 'ID', 'Time', 'none', 'username', 'Text']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [col for col in df.columns if not col.startswith('self')]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@StewartWade Yeah, I know--pigs for sure...which is a great visual on my end among all the akimbo-ness. ',\n",
       "       \"ouh @Babe_Franzi was hast du hun'? hoffentlich nichts schlimmes. yes, i miss you rlly much, mary too. \",\n",
       "       'Woke up with the worst headache ',\n",
       "       \"@MacekMakeupArt I can't remember the last movie I saw in a theatre!  Hope you guys have fun! What are you going to see?\",\n",
       "       'last day of classes   im going to miss chichi !',\n",
       "       'Damn, time for another pedicure, just chipped my toenail on an open cabinet  Shit happens!',\n",
       "       \"@mikegentile i've never been in a walmart  no joke\",\n",
       "       \"@amedelrivero Start putting up $100 every paycheck! We have to prepare ourselves for the future -_-. ONLY $300 is what i'm getting \",\n",
       "       '@patrickeatworld takboleh. i am so in loveeeeeeeeeeee  life sucks. FMMFL',\n",
       "       'I have church thur and am always forgetting I can watch fbc on line until Thurs. '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = np.array(df_sm['Text'])\n",
    "sentiments = np.array(df_sm['sentiment'])\n",
    "raw_text[5:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments[4995:5005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7udZhKkJnSCI"
   },
   "source": [
    "-----------------------\n",
    "\n",
    "# Data Cleaning\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-B4ADb4QCuL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APqmmwo8nSCJ"
   },
   "source": [
    "## Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctg2OlsXnSCK"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(s):\n",
    "    s = s.replace(r'<lb>', \"\\n\")\n",
    "    s = s.replace(r'<tab>', \"\\i\")\n",
    "    \n",
    "    # As a sanity check - s = s.replace(r'W', \"Q\")\n",
    "    \n",
    "    s = re.sub(r'<br */*>', \"\\n\", s)\n",
    "    s = s.replace(\"&lt;\", \"<\").replace(\"&gt;\", \">\").replace(\"&amp;\", \"&\")\n",
    "    s = s.replace(\"&amp;\", \"&\")\n",
    "    # markdown urls\n",
    "    s = re.sub(r'\\(https*://[^\\)]*\\)', \"\", s)\n",
    "    # normal urls\n",
    "    s = re.sub(r'https*://[^\\s]*', \"\", s)\n",
    "    s = re.sub(r'_+', ' ', s)\n",
    "    s = re.sub(r'\"+', '\"', s)\n",
    "    return str(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmUAz8ConSCP"
   },
   "source": [
    "## Create new column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0M6eW8LnSCQ"
   },
   "outputs": [],
   "source": [
    "df_sm[\"text_clean\"] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIWWygCBnSCU"
   },
   "source": [
    "# Iterate and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "177mRPBcnSCU",
    "outputId": "76c4023e-6491-41ba-ad12-9d1b34a313ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 798000\n",
      "processed: 799000\n",
      "processed: 800000\n",
      "processed: 801000\n"
     ]
    }
   ],
   "source": [
    "for i, row in df_sm.iterrows():\n",
    "    if i % 1000 == 0:\n",
    "            print('processed:'.format(i), i)\n",
    "    df_sm.at[i, \"text_clean\"] = clean(row.Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Ecr4awlnSCU"
   },
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "ukxXWf7onSCU",
    "outputId": "e2b12d10-743f-47e3-9362-51167b40b130"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>none</th>\n",
       "      <th>username</th>\n",
       "      <th>Text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>797999</td>\n",
       "      <td>0</td>\n",
       "      <td>2328378861</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>skelekitty</td>\n",
       "      <td>Work is so slow, I'm seriously considering quitting my job this week</td>\n",
       "      <td>Work is so slow, I'm seriously considering quitting my job this week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798000</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379014</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DjinniGenie</td>\n",
       "      <td>@davidvancamp That's awful.  I wish mine would stop making fat jokes.</td>\n",
       "      <td>@davidvancamp That's awful.  I wish mine would stop making fat jokes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798001</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379041</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Unrated7String</td>\n",
       "      <td>Well, i guess i need to start a new chapter in professional my life</td>\n",
       "      <td>Well, i guess i need to start a new chapter in professional my life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798002</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379271</td>\n",
       "      <td>Thu Jun 25 09:30:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jamesebradford</td>\n",
       "      <td>@SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.</td>\n",
       "      <td>@SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798003</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379299</td>\n",
       "      <td>Thu Jun 25 09:30:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>njandecrox</td>\n",
       "      <td>@CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt</td>\n",
       "      <td>@CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          ID                          Time      none  \\\n",
       "797999  0          2328378861  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798000  0          2328379014  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798001  0          2328379041  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798002  0          2328379271  Thu Jun 25 09:30:34 PDT 2009  NO_QUERY   \n",
       "798003  0          2328379299  Thu Jun 25 09:30:34 PDT 2009  NO_QUERY   \n",
       "\n",
       "              username  \\\n",
       "797999  skelekitty       \n",
       "798000  DjinniGenie      \n",
       "798001  Unrated7String   \n",
       "798002  jamesebradford   \n",
       "798003  njandecrox       \n",
       "\n",
       "                                                                                                                                     Text  \\\n",
       "797999  Work is so slow, I'm seriously considering quitting my job this week                                                                \n",
       "798000  @davidvancamp That's awful.  I wish mine would stop making fat jokes.                                                               \n",
       "798001  Well, i guess i need to start a new chapter in professional my life                                                                 \n",
       "798002  @SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.    \n",
       "798003  @CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt           \n",
       "\n",
       "                                                                                                                               text_clean  \n",
       "797999  Work is so slow, I'm seriously considering quitting my job this week                                                               \n",
       "798000  @davidvancamp That's awful.  I wish mine would stop making fat jokes.                                                              \n",
       "798001  Well, i guess i need to start a new chapter in professional my life                                                                \n",
       "798002  @SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.   \n",
       "798003  @CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt          "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional pre-processing: tokenization, removing extra whitespaces, lower casing and more advanced operations like spelling corrections, grammatical error corrections, removing repeated characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define normalization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm[\"text_normalized\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 798000\n",
      "processed: 799000\n",
      "processed: 800000\n",
      "processed: 801000\n"
     ]
    }
   ],
   "source": [
    "for i, row in df_sm.iterrows():\n",
    "    if i % 1000 == 0:\n",
    "            print('processed:'.format(i), i)\n",
    "    df_sm.at[i, \"text_normalized\"] = normalize_corpus(row.text_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>none</th>\n",
       "      <th>username</th>\n",
       "      <th>Text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>797999</td>\n",
       "      <td>0</td>\n",
       "      <td>2328378861</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>skelekitty</td>\n",
       "      <td>Work is so slow, I'm seriously considering quitting my job this week</td>\n",
       "      <td>Work is so slow, I'm seriously considering quitting my job this week</td>\n",
       "      <td>work slow im seriously considering quitting job week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798000</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379014</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DjinniGenie</td>\n",
       "      <td>@davidvancamp That's awful.  I wish mine would stop making fat jokes.</td>\n",
       "      <td>@davidvancamp That's awful.  I wish mine would stop making fat jokes.</td>\n",
       "      <td>davidvancamp thats awful . wish mine would stop making fat jokes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798001</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379041</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Unrated7String</td>\n",
       "      <td>Well, i guess i need to start a new chapter in professional my life</td>\n",
       "      <td>Well, i guess i need to start a new chapter in professional my life</td>\n",
       "      <td>well guess need start new chapter professional life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798002</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379271</td>\n",
       "      <td>Thu Jun 25 09:30:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jamesebradford</td>\n",
       "      <td>@SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.</td>\n",
       "      <td>@SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.</td>\n",
       "      <td>sandrabernhard miss lady since brought web store - notoriously known takes ages rec ' v merch .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798003</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379299</td>\n",
       "      <td>Thu Jun 25 09:30:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>njandecrox</td>\n",
       "      <td>@CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt</td>\n",
       "      <td>@CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt</td>\n",
       "      <td>cartertwinszach im sorry hope u feel better cuz love u makes feel horrible ur sick sad mad hurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801994</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163268</td>\n",
       "      <td>Tue Apr 07 00:03:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jerichoK</td>\n",
       "      <td>@FizzyDuck Five? Seems a little bit too late in the morning but what the hell !</td>\n",
       "      <td>@FizzyDuck Five? Seems a little bit too late in the morning but what the hell !</td>\n",
       "      <td>fizzyduck five seems little bit late morning hell !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801995</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163291</td>\n",
       "      <td>Tue Apr 07 00:03:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ex1up</td>\n",
       "      <td>ryanodonnell: @AttractMode Thanks for putting on such a great event. Can't wait for the inevitable sequels!  [.. http://tinyurl.com/c3e3ub</td>\n",
       "      <td>ryanodonnell: @AttractMode Thanks for putting on such a great event. Can't wait for the inevitable sequels!  [..</td>\n",
       "      <td>ryanodonnell attractmode thanks putting great event . ' wait inevitable sequels ! [..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801996</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163300</td>\n",
       "      <td>Tue Apr 07 00:03:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Mmmbaileys</td>\n",
       "      <td>@damygeebo Carli's my friend</td>\n",
       "      <td>@damygeebo Carli's my friend</td>\n",
       "      <td>damygeebo carlis friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801997</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163315</td>\n",
       "      <td>Tue Apr 07 00:03:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jasminejoejonas</td>\n",
       "      <td>I feel so great for starting twitter at suzanne  but still hardly anyone has it.</td>\n",
       "      <td>I feel so great for starting twitter at suzanne  but still hardly anyone has it.</td>\n",
       "      <td>feel great starting twitter suzanne still hardly anyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801998</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163384</td>\n",
       "      <td>Tue Apr 07 00:03:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>rsuenaga</td>\n",
       "      <td>@Luke_Stephens: I just said I was wondering about it, not that I wanted it.</td>\n",
       "      <td>@Luke Stephens: I just said I was wondering about it, not that I wanted it.</td>\n",
       "      <td>luke stephens said wondering , wanted .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          ID                          Time      none  \\\n",
       "797999  0          2328378861  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798000  0          2328379014  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798001  0          2328379041  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798002  0          2328379271  Thu Jun 25 09:30:34 PDT 2009  NO_QUERY   \n",
       "798003  0          2328379299  Thu Jun 25 09:30:34 PDT 2009  NO_QUERY   \n",
       "...    ..                 ...                           ...       ...   \n",
       "801994  4          1468163268  Tue Apr 07 00:03:40 PDT 2009  NO_QUERY   \n",
       "801995  4          1468163291  Tue Apr 07 00:03:40 PDT 2009  NO_QUERY   \n",
       "801996  4          1468163300  Tue Apr 07 00:03:39 PDT 2009  NO_QUERY   \n",
       "801997  4          1468163315  Tue Apr 07 00:03:39 PDT 2009  NO_QUERY   \n",
       "801998  4          1468163384  Tue Apr 07 00:03:40 PDT 2009  NO_QUERY   \n",
       "\n",
       "               username  \\\n",
       "797999  skelekitty        \n",
       "798000  DjinniGenie       \n",
       "798001  Unrated7String    \n",
       "798002  jamesebradford    \n",
       "798003  njandecrox        \n",
       "...            ...        \n",
       "801994  jerichoK          \n",
       "801995  ex1up             \n",
       "801996  Mmmbaileys        \n",
       "801997  jasminejoejonas   \n",
       "801998  rsuenaga          \n",
       "\n",
       "                                                                                                                                              Text  \\\n",
       "797999  Work is so slow, I'm seriously considering quitting my job this week                                                                         \n",
       "798000  @davidvancamp That's awful.  I wish mine would stop making fat jokes.                                                                        \n",
       "798001  Well, i guess i need to start a new chapter in professional my life                                                                          \n",
       "798002  @SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.             \n",
       "798003  @CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt                    \n",
       "...                                                                                                                            ...                   \n",
       "801994  @FizzyDuck Five? Seems a little bit too late in the morning but what the hell !                                                              \n",
       "801995  ryanodonnell: @AttractMode Thanks for putting on such a great event. Can't wait for the inevitable sequels!  [.. http://tinyurl.com/c3e3ub   \n",
       "801996  @damygeebo Carli's my friend                                                                                                                 \n",
       "801997  I feel so great for starting twitter at suzanne  but still hardly anyone has it.                                                             \n",
       "801998  @Luke_Stephens: I just said I was wondering about it, not that I wanted it.                                                                  \n",
       "\n",
       "                                                                                                                               text_clean  \\\n",
       "797999  Work is so slow, I'm seriously considering quitting my job this week                                                                \n",
       "798000  @davidvancamp That's awful.  I wish mine would stop making fat jokes.                                                               \n",
       "798001  Well, i guess i need to start a new chapter in professional my life                                                                 \n",
       "798002  @SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.    \n",
       "798003  @CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt           \n",
       "...                                                                                                                            ...          \n",
       "801994  @FizzyDuck Five? Seems a little bit too late in the morning but what the hell !                                                     \n",
       "801995  ryanodonnell: @AttractMode Thanks for putting on such a great event. Can't wait for the inevitable sequels!  [..                    \n",
       "801996  @damygeebo Carli's my friend                                                                                                        \n",
       "801997  I feel so great for starting twitter at suzanne  but still hardly anyone has it.                                                    \n",
       "801998  @Luke Stephens: I just said I was wondering about it, not that I wanted it.                                                         \n",
       "\n",
       "                                                                                        text_normalized  \n",
       "797999  work slow im seriously considering quitting job week                                             \n",
       "798000  davidvancamp thats awful . wish mine would stop making fat jokes .                               \n",
       "798001  well guess need start new chapter professional life                                              \n",
       "798002  sandrabernhard miss lady since brought web store - notoriously known takes ages rec ' v merch .  \n",
       "798003  cartertwinszach im sorry hope u feel better cuz love u makes feel horrible ur sick sad mad hurt  \n",
       "...                                                                                                 ...  \n",
       "801994  fizzyduck five seems little bit late morning hell !                                              \n",
       "801995  ryanodonnell attractmode thanks putting great event . ' wait inevitable sequels ! [..            \n",
       "801996  damygeebo carlis friend                                                                          \n",
       "801997  feel great starting twitter suzanne still hardly anyone                                          \n",
       "801998  luke stephens said wondering , wanted .                                                          \n",
       "\n",
       "[4000 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798000\n",
      "799000\n",
      "800000\n",
      "801000\n"
     ]
    }
   ],
   "source": [
    "for i, row in df_sm.iterrows():\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    if(row[\"text_normalized\"] and len(str(row[\"text_normalized\"])) < 1000000):\n",
    "        doc = nlp(str(row[\"text_normalized\"]))\n",
    "        adjectives = []\n",
    "        nouns = []\n",
    "        verbs = []\n",
    "        lemmas = []\n",
    "\n",
    "        for token in doc:\n",
    "            lemmas.append(token.lemma_)\n",
    "            if token.pos_ == \"ADJ\":\n",
    "                adjectives.append(token.lemma_)\n",
    "            if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n",
    "                nouns.append(token.lemma_)\n",
    "            if token.pos_ == \"VERB\":\n",
    "                verbs.append(token.lemma_)\n",
    "                \n",
    "        df_sm.at[i, \"text_lemma\"] = \" \".join(lemmas)                \n",
    "        df_sm.at[i, \"text_nouns\"] = \" \".join(nouns)\n",
    "        df_sm.at[i, \"text_adjectives\"] = \" \".join(adjectives)\n",
    "        df_sm.at[i, \"text_verbs\"] = \" \".join(verbs)\n",
    "        df_sm.at[i, \"text_nav\"] = \" \".join(nouns+adjectives+verbs)\n",
    "        df_sm.at[i, \"no_tokens\"] = len(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>none</th>\n",
       "      <th>username</th>\n",
       "      <th>Text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>text_nouns</th>\n",
       "      <th>text_adjectives</th>\n",
       "      <th>text_verbs</th>\n",
       "      <th>text_nav</th>\n",
       "      <th>no_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>797999</td>\n",
       "      <td>0</td>\n",
       "      <td>2328378861</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>skelekitty</td>\n",
       "      <td>Work is so slow, I'm seriously considering quitting my job this week</td>\n",
       "      <td>Work is so slow, I'm seriously considering quitting my job this week</td>\n",
       "      <td>work slow im seriously considering quitting job week</td>\n",
       "      <td>work slow -PRON- be seriously consider quit job week</td>\n",
       "      <td>work job week</td>\n",
       "      <td>slow</td>\n",
       "      <td>be consider quit</td>\n",
       "      <td>work job week slow be consider quit</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798000</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379014</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DjinniGenie</td>\n",
       "      <td>@davidvancamp That's awful.  I wish mine would stop making fat jokes.</td>\n",
       "      <td>@davidvancamp That's awful.  I wish mine would stop making fat jokes.</td>\n",
       "      <td>davidvancamp thats awful . wish mine would stop making fat jokes .</td>\n",
       "      <td>davidvancamp that s awful . wish mine would stop make fat joke .</td>\n",
       "      <td>davidvancamp wish mine joke</td>\n",
       "      <td>awful fat</td>\n",
       "      <td>s would stop make</td>\n",
       "      <td>davidvancamp wish mine joke awful fat s would stop make</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798001</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379041</td>\n",
       "      <td>Thu Jun 25 09:30:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Unrated7String</td>\n",
       "      <td>Well, i guess i need to start a new chapter in professional my life</td>\n",
       "      <td>Well, i guess i need to start a new chapter in professional my life</td>\n",
       "      <td>well guess need start new chapter professional life</td>\n",
       "      <td>well guess nee start new chapter professional life</td>\n",
       "      <td>chapter professional life</td>\n",
       "      <td>new</td>\n",
       "      <td>guess nee start</td>\n",
       "      <td>chapter professional life new guess nee start</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798002</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379271</td>\n",
       "      <td>Thu Jun 25 09:30:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jamesebradford</td>\n",
       "      <td>@SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.</td>\n",
       "      <td>@SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.</td>\n",
       "      <td>sandrabernhard miss lady since brought web store - notoriously known takes ages rec ' v merch .</td>\n",
       "      <td>sandrabernhard miss lady since bring web store - notoriously know take age rec ' v merch .</td>\n",
       "      <td>sandrabernhard miss lady web store age rec v merch</td>\n",
       "      <td></td>\n",
       "      <td>bring know take</td>\n",
       "      <td>sandrabernhard miss lady web store age rec v merch bring know take</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798003</td>\n",
       "      <td>0</td>\n",
       "      <td>2328379299</td>\n",
       "      <td>Thu Jun 25 09:30:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>njandecrox</td>\n",
       "      <td>@CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt</td>\n",
       "      <td>@CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt</td>\n",
       "      <td>cartertwinszach im sorry hope u feel better cuz love u makes feel horrible ur sick sad mad hurt</td>\n",
       "      <td>cartertwinszach -PRON- be sorry hope u feel better cuz love u make feel horrible ur sick sad mad hurt</td>\n",
       "      <td>cartertwinszach hope love hurt</td>\n",
       "      <td>sorry horrible sick sad mad</td>\n",
       "      <td>be feel make feel</td>\n",
       "      <td>cartertwinszach hope love hurt sorry horrible sick sad mad be feel make feel</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801994</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163268</td>\n",
       "      <td>Tue Apr 07 00:03:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jerichoK</td>\n",
       "      <td>@FizzyDuck Five? Seems a little bit too late in the morning but what the hell !</td>\n",
       "      <td>@FizzyDuck Five? Seems a little bit too late in the morning but what the hell !</td>\n",
       "      <td>fizzyduck five seems little bit late morning hell !</td>\n",
       "      <td>fizzyduck five seem little bit late morning hell !</td>\n",
       "      <td>fizzyduck bit morning hell</td>\n",
       "      <td>little late</td>\n",
       "      <td>seem</td>\n",
       "      <td>fizzyduck bit morning hell little late seem</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801995</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163291</td>\n",
       "      <td>Tue Apr 07 00:03:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ex1up</td>\n",
       "      <td>ryanodonnell: @AttractMode Thanks for putting on such a great event. Can't wait for the inevitable sequels!  [.. http://tinyurl.com/c3e3ub</td>\n",
       "      <td>ryanodonnell: @AttractMode Thanks for putting on such a great event. Can't wait for the inevitable sequels!  [..</td>\n",
       "      <td>ryanodonnell attractmode thanks putting great event . ' wait inevitable sequels ! [..</td>\n",
       "      <td>ryanodonnell attractmode thank put great event . ' wait inevitable sequel ! [ ..</td>\n",
       "      <td>ryanodonnell thank event sequel</td>\n",
       "      <td>great inevitable</td>\n",
       "      <td>attractmode put wait</td>\n",
       "      <td>ryanodonnell thank event sequel great inevitable attractmode put wait</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801996</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163300</td>\n",
       "      <td>Tue Apr 07 00:03:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Mmmbaileys</td>\n",
       "      <td>@damygeebo Carli's my friend</td>\n",
       "      <td>@damygeebo Carli's my friend</td>\n",
       "      <td>damygeebo carlis friend</td>\n",
       "      <td>damygeebo carlis friend</td>\n",
       "      <td>damygeebo carlis friend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>damygeebo carlis friend</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801997</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163315</td>\n",
       "      <td>Tue Apr 07 00:03:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jasminejoejonas</td>\n",
       "      <td>I feel so great for starting twitter at suzanne  but still hardly anyone has it.</td>\n",
       "      <td>I feel so great for starting twitter at suzanne  but still hardly anyone has it.</td>\n",
       "      <td>feel great starting twitter suzanne still hardly anyone</td>\n",
       "      <td>feel great start twitt suzanne still hardly anyone</td>\n",
       "      <td>suzanne</td>\n",
       "      <td>great twitt</td>\n",
       "      <td>feel start</td>\n",
       "      <td>suzanne great twitt feel start</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801998</td>\n",
       "      <td>4</td>\n",
       "      <td>1468163384</td>\n",
       "      <td>Tue Apr 07 00:03:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>rsuenaga</td>\n",
       "      <td>@Luke_Stephens: I just said I was wondering about it, not that I wanted it.</td>\n",
       "      <td>@Luke Stephens: I just said I was wondering about it, not that I wanted it.</td>\n",
       "      <td>luke stephens said wondering , wanted .</td>\n",
       "      <td>luke stephens say wonder , want .</td>\n",
       "      <td>luke stephens</td>\n",
       "      <td></td>\n",
       "      <td>say wonder want</td>\n",
       "      <td>luke stephens say wonder want</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          ID                          Time      none  \\\n",
       "797999  0          2328378861  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798000  0          2328379014  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798001  0          2328379041  Thu Jun 25 09:30:33 PDT 2009  NO_QUERY   \n",
       "798002  0          2328379271  Thu Jun 25 09:30:34 PDT 2009  NO_QUERY   \n",
       "798003  0          2328379299  Thu Jun 25 09:30:34 PDT 2009  NO_QUERY   \n",
       "...    ..                 ...                           ...       ...   \n",
       "801994  4          1468163268  Tue Apr 07 00:03:40 PDT 2009  NO_QUERY   \n",
       "801995  4          1468163291  Tue Apr 07 00:03:40 PDT 2009  NO_QUERY   \n",
       "801996  4          1468163300  Tue Apr 07 00:03:39 PDT 2009  NO_QUERY   \n",
       "801997  4          1468163315  Tue Apr 07 00:03:39 PDT 2009  NO_QUERY   \n",
       "801998  4          1468163384  Tue Apr 07 00:03:40 PDT 2009  NO_QUERY   \n",
       "\n",
       "               username  \\\n",
       "797999  skelekitty        \n",
       "798000  DjinniGenie       \n",
       "798001  Unrated7String    \n",
       "798002  jamesebradford    \n",
       "798003  njandecrox        \n",
       "...            ...        \n",
       "801994  jerichoK          \n",
       "801995  ex1up             \n",
       "801996  Mmmbaileys        \n",
       "801997  jasminejoejonas   \n",
       "801998  rsuenaga          \n",
       "\n",
       "                                                                                                                                              Text  \\\n",
       "797999  Work is so slow, I'm seriously considering quitting my job this week                                                                         \n",
       "798000  @davidvancamp That's awful.  I wish mine would stop making fat jokes.                                                                        \n",
       "798001  Well, i guess i need to start a new chapter in professional my life                                                                          \n",
       "798002  @SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.             \n",
       "798003  @CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt                    \n",
       "...                                                                                                                            ...                   \n",
       "801994  @FizzyDuck Five? Seems a little bit too late in the morning but what the hell !                                                              \n",
       "801995  ryanodonnell: @AttractMode Thanks for putting on such a great event. Can't wait for the inevitable sequels!  [.. http://tinyurl.com/c3e3ub   \n",
       "801996  @damygeebo Carli's my friend                                                                                                                 \n",
       "801997  I feel so great for starting twitter at suzanne  but still hardly anyone has it.                                                             \n",
       "801998  @Luke_Stephens: I just said I was wondering about it, not that I wanted it.                                                                  \n",
       "\n",
       "                                                                                                                               text_clean  \\\n",
       "797999  Work is so slow, I'm seriously considering quitting my job this week                                                                \n",
       "798000  @davidvancamp That's awful.  I wish mine would stop making fat jokes.                                                               \n",
       "798001  Well, i guess i need to start a new chapter in professional my life                                                                 \n",
       "798002  @SandraBernhard Miss Lady, since you brought up your web store - it is notoriously known that it takes AGES to rec'v your merch.    \n",
       "798003  @CarterTwinsZach Im sorry I hope u feel better cuz I love u and it makes feel horrible when ur sick or sad or mad or hurt           \n",
       "...                                                                                                                            ...          \n",
       "801994  @FizzyDuck Five? Seems a little bit too late in the morning but what the hell !                                                     \n",
       "801995  ryanodonnell: @AttractMode Thanks for putting on such a great event. Can't wait for the inevitable sequels!  [..                    \n",
       "801996  @damygeebo Carli's my friend                                                                                                        \n",
       "801997  I feel so great for starting twitter at suzanne  but still hardly anyone has it.                                                    \n",
       "801998  @Luke Stephens: I just said I was wondering about it, not that I wanted it.                                                         \n",
       "\n",
       "                                                                                        text_normalized  \\\n",
       "797999  work slow im seriously considering quitting job week                                              \n",
       "798000  davidvancamp thats awful . wish mine would stop making fat jokes .                                \n",
       "798001  well guess need start new chapter professional life                                               \n",
       "798002  sandrabernhard miss lady since brought web store - notoriously known takes ages rec ' v merch .   \n",
       "798003  cartertwinszach im sorry hope u feel better cuz love u makes feel horrible ur sick sad mad hurt   \n",
       "...                                                                                                 ...   \n",
       "801994  fizzyduck five seems little bit late morning hell !                                               \n",
       "801995  ryanodonnell attractmode thanks putting great event . ' wait inevitable sequels ! [..             \n",
       "801996  damygeebo carlis friend                                                                           \n",
       "801997  feel great starting twitter suzanne still hardly anyone                                           \n",
       "801998  luke stephens said wondering , wanted .                                                           \n",
       "\n",
       "                                                                                                   text_lemma  \\\n",
       "797999  work slow -PRON- be seriously consider quit job week                                                    \n",
       "798000  davidvancamp that s awful . wish mine would stop make fat joke .                                        \n",
       "798001  well guess nee start new chapter professional life                                                      \n",
       "798002  sandrabernhard miss lady since bring web store - notoriously know take age rec ' v merch .              \n",
       "798003  cartertwinszach -PRON- be sorry hope u feel better cuz love u make feel horrible ur sick sad mad hurt   \n",
       "...                                                                                                       ...   \n",
       "801994  fizzyduck five seem little bit late morning hell !                                                      \n",
       "801995  ryanodonnell attractmode thank put great event . ' wait inevitable sequel ! [ ..                        \n",
       "801996  damygeebo carlis friend                                                                                 \n",
       "801997  feel great start twitt suzanne still hardly anyone                                                      \n",
       "801998  luke stephens say wonder , want .                                                                       \n",
       "\n",
       "                                                text_nouns  \\\n",
       "797999  work job week                                        \n",
       "798000  davidvancamp wish mine joke                          \n",
       "798001  chapter professional life                            \n",
       "798002  sandrabernhard miss lady web store age rec v merch   \n",
       "798003  cartertwinszach hope love hurt                       \n",
       "...                                ...                       \n",
       "801994  fizzyduck bit morning hell                           \n",
       "801995  ryanodonnell thank event sequel                      \n",
       "801996  damygeebo carlis friend                              \n",
       "801997  suzanne                                              \n",
       "801998  luke stephens                                        \n",
       "\n",
       "                    text_adjectives            text_verbs  \\\n",
       "797999  slow                         be consider quit       \n",
       "798000  awful fat                    s would stop make      \n",
       "798001  new                          guess nee start        \n",
       "798002                               bring know take        \n",
       "798003  sorry horrible sick sad mad  be feel make feel      \n",
       "...                             ...                ...      \n",
       "801994  little late                  seem                   \n",
       "801995  great inevitable             attractmode put wait   \n",
       "801996                                                      \n",
       "801997  great twitt                  feel start             \n",
       "801998                               say wonder want        \n",
       "\n",
       "                                                                            text_nav  \\\n",
       "797999  work job week slow be consider quit                                            \n",
       "798000  davidvancamp wish mine joke awful fat s would stop make                        \n",
       "798001  chapter professional life new guess nee start                                  \n",
       "798002  sandrabernhard miss lady web store age rec v merch bring know take             \n",
       "798003  cartertwinszach hope love hurt sorry horrible sick sad mad be feel make feel   \n",
       "...                                                                              ...   \n",
       "801994  fizzyduck bit morning hell little late seem                                    \n",
       "801995  ryanodonnell thank event sequel great inevitable attractmode put wait          \n",
       "801996  damygeebo carlis friend                                                        \n",
       "801997  suzanne great twitt feel start                                                 \n",
       "801998  luke stephens say wonder want                                                  \n",
       "\n",
       "        no_tokens  \n",
       "797999 9.00        \n",
       "798000 13.00       \n",
       "798001 8.00        \n",
       "798002 17.00       \n",
       "798003 19.00       \n",
       "...      ...       \n",
       "801994 9.00        \n",
       "801995 14.00       \n",
       "801996 3.00        \n",
       "801997 8.00        \n",
       "801998 7.00        \n",
       "\n",
       "[4000 rows x 14 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "# Explore data\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "explore_text = np.array(df_sm['text_normalized'])\n",
    "fdist = FreqDist(explore_text)\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Afinn\n",
    "\n",
    "As a quick and dirty sanity check, I've set up Afinn in the early stages of data cleaning, and intend to keep a little record of Afinn's performance, as I increase the rigour of the data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.array(df_sm['text_clean'])\n",
    "sentiments = np.array(df_sm['sentiment'])\n",
    "\n",
    "# extract data for model evaluation\n",
    "#train_texts = texts[:10000]\n",
    "#train_sentiments = sentiments[:10000]\n",
    "\n",
    "#test_texts = texts[40000:60000]\n",
    "#test_sentiments = sentiments[40000:60000]\n",
    "sample_ids = [626, 533, 310, 123, 654, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_clean, sentiment in zip(texts[sample_ids], sentiments[sample_ids]):\n",
    "    print('TEXT:', texts)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity:', afn.score(texts))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment with Afinn\n",
    "\n",
    "sentiment_polarity = [afn.score(Text) for Text in normalized_texts]\n",
    "#predicted_sentiments = ['positive' if score >= 1.0 else 'negative' for score in sentiment_polarity]\n",
    "predicted_sentiments = [4 if score >= 1.0 else 0 for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meu.display_model_performance_metrics(true_labels=test_texts, predicted_labels=predicted_sentiments, \n",
    "#                                  classes=['positive', 'negative'])\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=[4, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking cleaning with Afinn\n",
    "\n",
    "I'm curious about how deeper cleaning affects predicitive models. So I set up Afinn after the very first round of data cleaning, and am going to track results here in the markdown. For simplicity, I will monitor the effects of different levels of cleaning on \"weighted avg f1-score\"\n",
    "\n",
    "Round 1, most basic cleaning, 20000 rows:  0.63\n",
    "\n",
    "Round 2, include normalization, 20000 rows: 0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = np.array(df_sm['text_normalized'])\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(texts)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names()\n",
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L75iqChDnSCe"
   },
   "source": [
    "#### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ynhqSwDunSCe"
   },
   "source": [
    "## Load spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMNfxFA1nSCe"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1l-paPPnSCe"
   },
   "source": [
    "## Iterate over all rows and perform NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "7IGiQ5hfnSCe",
    "outputId": "5170760f-a771-4c10-8a66-51fc279ba9d1"
   },
   "outputs": [],
   "source": [
    "for i, row in df_sm.iterrows():\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    if(row[\"text_clean\"] and len(str(row[\"text_clean\"])) < 1000000):\n",
    "        doc = nlp(str(row[\"text_clean\"]))\n",
    "        adjectives = []\n",
    "        nouns = []\n",
    "        verbs = []\n",
    "        lemmas = []\n",
    "\n",
    "        for token in doc:\n",
    "            lemmas.append(token.lemma_)\n",
    "            if token.pos_ == \"ADJ\":\n",
    "                adjectives.append(token.lemma_)\n",
    "            if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n",
    "                nouns.append(token.lemma_)\n",
    "            if token.pos_ == \"VERB\":\n",
    "                verbs.append(token.lemma_)\n",
    "                \n",
    "        df_sm.at[i, \"selftext_lemma\"] = \" \".join(lemmas)                \n",
    "        df_sm.at[i, \"selftext_nouns\"] = \" \".join(nouns)\n",
    "        df_sm.at[i, \"selftext_adjectives\"] = \" \".join(adjectives)\n",
    "        df_sm.at[i, \"selftext_verbs\"] = \" \".join(verbs)\n",
    "        df_sm.at[i, \"selftext_nav\"] = \" \".join(nouns+adjectives+verbs)\n",
    "        df_sm.at[i, \"no_tokens\"] = len(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQdL3PkynSCo"
   },
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "I9_JnCudnSCo",
    "outputId": "e6b101dc-9e29-49c5-e721-777e4557609a"
   },
   "outputs": [],
   "source": [
    "df_sm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aa6qxMhqnSCo"
   },
   "source": [
    "## Save to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jFdiqd0WnSCy"
   },
   "outputs": [],
   "source": [
    "df.to_sql('posts_nlp', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWaPk57LqDRV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tImPFlPIqG5f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "csml1010-pete-gray.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
